DAY 13 - 8th October

---
@ control-plane
---

Your Kubernetes control-plane has initialized successfully!

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


Token :
 
kubeadm join 172.31.2.57:6443 --token xy8yju.tnrnbwr1w8g0f9dp --discovery-token-ca-cert-hash sha256:2bd72c6dd26712ba05bfdec867a0b0238a346a469c2c623c5231171287104a47

______________
@node-one
______________

kubeadm join 172.31.2.57:6443 --token xy8yju.tnrnbwr1w8g0f9dp --discovery-token-ca-cert-hash sha256:2bd72c6dd26712ba05bfdec867a0b0238a346a469c2c623c5231171287104a47

______________
@node-two
______________

kubeadm join 172.31.2.57:6443 --token xy8yju.tnrnbwr1w8g0f9dp --discovery-token-ca-cert-hash sha256:2bd72c6dd26712ba05bfdec867a0b0238a346a469c2c623c5231171287104a47

---
@ control-plane
---
Configure Pod Network
__________
curl https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/calico.yaml -O

kubectl apply -f calico.yaml

# kubectl get pod -A
# kubectl get nodes -o wide

________________________________________




__________________________________
Pod Quality of Service
__________________________________

Doc - https://kubernetes.io/docs/tasks/configure-pod-container/

--> BestEffort QoS -->

_______________________
@ controller-plane @
_______________________

# mkdir /k8s-code
# cd  /k8s-code
# vim my-firstpod.yaml
// QoS - Best Efforts

"
apiVersion: v1
kind: Pod
metadata:
  name: devops
spec:
  containers:
  - name: web-app
    image: nginx:1.14
    ports:
    - containerPort : 80
"
#kubectl apply -f my-fisrtpod.yaml
# kubectl get pod
# kubectl describe pod devops
# cp my-firstpod.yaml second-pod.yaml
# ll
# kubectl get pod
# kubectl get ns
# vim second-pod.yaml

"
apiVersion: v1
kind: Pod
metadata:
  name: prod-pod
spec:
  containers:
  - name: web-app
    image: nginx:1.14
    ports:
    - containerPort : 80

"
#kubectl apply -f second-pod.yaml
# kubectl get pod
# kubectl describe pod prod-pod
# kubectl describe pod prod-pod | grep -i controlled
 > Blank as there's no  controller over the pod
# kubectl describe pod prod-pod


# vim my-firstpod.yaml
// https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/

"
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
  - name: web-app
    image: nginx:1.14
    ports:
    - containerPort : 80
    resources:
      requests:
        memory: "100Mi"
      limits:
        memory: "200Mi"
 
"

# kubectl apply -f my-firstpod.yaml
# kubectl get pod
# kubectl describe pod test-pod

--> Burstable QoS --> in yaml file you can have only cpu or memory or both but with different limits

# vim burstable-pod.yaml
>
"

apiVersion: v1
kind: Pod
metadata:
  name: production

spec:
  containers:
  - name: k8s-app
    image: nginx:1.14
    resources:
      requests:
 	memory: "50Mi"
 	cpu: "0.2"
      limits:
 	memory: "100Mi"
 	cpu: "0.4"
 
"
# kubectl apply -f burstbale-pod.yaml
# kubectl get pod produciton
# kubectl describe pod production

# vim cpu-burstable.yaml
>
"
apiVersion: v1
kind: Pod
metadata:
  name: dev-en

spec:
  containers:
  - name: dev-env
    image: vish/stress
    resources:
      requests:
 	cpu: "0.2"
    limits:
 	cpu: "0.4"

"
# kubectl apply -f cpu-burstable.yaml
# kubectl get pod dev-en
# kubectl describe pod dev-en


--> Guaranteed QoS -->
in yaml file both cpu and memory are required and limit also must be same

kubectl get pod -o wide
# vim garrented-pod.yaml
>
"
apiVersion: v1
kind: Pod
metadata:
  name: operation-pod

spec:
  containers:
  - name: operation-app
    image: images.my-company.example/log-aggregator:v6
    resources:
      requests:
 	memory: "100Mi"
      limits:
 	memory: "100Mi"

"
# kubectl apply -f garrented-pod.yaml
# kubectl get pod
>ImagePullBackOff error
# kubectl delete pod operation-pod
# vim garrented-pod.yaml
>
"
apiVersion: v1
kind: Pod
metadata:
  name: operation-pod

spec:
  containers:
  - name: operation-app
    image: httpd
    resources:
      requests:
 	memory: "100Mi"
 	cpu: "1.0"
      limits:
 	memory: "100Mi"
 	cpu: "1.0"

"
# kubectl apply -f garrented-pod.yaml
# kubectl get pod
# kubectl describe pod operation-pod


After Lunch
______________________
__________________
Creating MySQL Pod
//Pending
__________________

# cd /k8s-code/
# vim database-pod.yaml
#


// Google - How to get containers from pod
# kubectl get pod                            | Not
# kubectl exec -it dbpod -- /bin/bash        | Right Appr.

How to put Controller On Pods
//Pending
_______________________________________________________

> Google : Kubernetes controller > kio

> Kio : Replicaset

_________________________________________________________

_________________________
Replica-Set in Kubernetes
_______________________________________

# vim devops-rs.yaml
> https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
"
apiVersion: apps/v1
kind: ReplicaSet
metadata:
 name: devops-rs
 labels:
  app: devops-rs
  tier: prod
spec:
 replicas: 3
 selector:
  matchLabels:
   tier: prod
 template:
  metadata:
   labels:
    tier: prod
  spec:
   containers:
    - name: web-apache
      image: nginx

"

# mv devops-rs.yaml /k8s-code/
# cd /k8s-code/
# kubectl apply -f devops-rs.yaml
#
#
#
# kubectl get pod
#
# kubectl get rs
# kubectl describe rs devops-rs
#


_____________________
Scaling in Kubernetes
_________________________________

________________
VERTICAL SCALING
________________

# vim devops-rs.yaml
>
"
apiVersion: apps/v1
kind: ReplicaSet
metadata:
 name: devops-rs
 labels:
  app: devops-rs
  tier: prod
spec:
 replicas: 8
 selector:
  matchLabels:
   tier: prod
 template:
  metadata:
   labels:
    tier: prod
  spec:
   containers:
    - name: web-apache
      image: nginx

"

# kubectl apply -f devops-rs.yaml
# watch kubectl get pod // freezes on get pod

@ TAke a duplicate terminal @
# cd /k8s-code/
# kubectl get pod
# kubectl scale replicaset devops-rs --replicas=10

_________________________
HORIZONTAL SCALING- HPA
_________________________

# vim my-hpa.yaml
> https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/ 
> hpa-rs.yaml -> Refer to this file on the documentation & use only the names from below.
"
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: devops-scaler
spec:
scaleTargetRef:
apiVersion: apps/v1
kind: ReplicaSet
    name: devops-rs
  minReplicas: 3
  maxReplicas: 10
targetCPUUtilizationPercentage: 25

"

>

# kubectl apply -f my-hpa.yaml
-> check # kubectl get pod in Frozen terminal
# kubectl get hpa
# kubectl delete hpa devops-scaler
# kubectl scale replicaset devops-rs --replicas=2
-> check in Frozen terminal
# kubectl apply -f my-hpa.yaml
# kubectl get hpa

>


//Isolating pods from a replica set // Pending
_________________________________________________

# kubectl describe rs devops-rs
-> Copy label
# kubectl label pod <pod-name> app=debug --overwrite
# kubectl describe pod <pod-name>
# kubectl get rs
# kubectl label pod <pod-name> app-
#
_____________________________________________________

> Google - Replicaset in Kubernetes architecture diagram


# kubectl delete rs devops-rs
# kubectl get rs

-> check in Frozen terminal
// We don't work with replica set in real environment
Rather we use deployment - Basically write a Manifest file for deployment


________________
DEPLOYMENT
_______________

// Deployment in Kubernetes architecture diagram
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ - Checked

> controllers/nginx-deployment.yaml > yaml file name

# vim my-deploy.yaml
"

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: web
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
"

# kubectl apply -f my-deploy.yaml
# kubectl get deploy
# kubectl get rs
# kubectl get po
# kubectl describe deployments

> Deployment autoscaling in Kubernetes

-> set replicas : 1 in my-deploy.yaml
kubectl apply -f my-deploy.yaml
-> Check in frozen terminal
# vim deployment-hpa.yaml
> Follow Picture indentation
"
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
scaleTargetRef:
    apiVersion: apps/v1
kind: Deployment
    name: nginx-deployment
minReplicas: 4
maxReplicas: 10
metrics:
- type: Resource
resource:
        name: cpu
target:
          type: Utilization
          averageUtilization: 25
"
>
# kubectl apply -f deployment-hpa.yaml
-> Check in Frozen Terminal
